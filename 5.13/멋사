{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 10기 멋쟁이 사자처럼 python 과제_정답\n",
    "<br>\n",
    "<div style = \"font-weight: 800;\">\n",
    "<ol>\n",
    "<li>이름: 김준서</li>\n",
    "<li>2019313442</li>\n",
    "<li>통계학과</li>\n",
    "<li>2022-04-16</li>\n",
    "<br>\n",
    "<ol>\n",
    "</div>\n",
    "\n",
    "<h3>크롤링하기:</h3>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem1 \n",
    "### 문제1\n",
    "<div style = \"margin-top:30px\">\n",
    "영화 목록 API를 이용하여 감독의 이름이 \"봉준호\"인 영화의 목록을 받아 데이터 프레임을 생성한 후, 'prdtYear'변수를 기준으로 오름차순을 정렬하세요. 'directors'컬럼과 'companys'컬럼은 이름만 남도록 변경해주세요.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from urllib.parse import urlencode, quote_plus\n",
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import bs4\n",
    "import json\n",
    "\n",
    "key = 'a8e597633acca03091ad5fba598b58a7'\n",
    "url = \"http://kobis.or.kr/kobisopenapi/webservice/rest/movie/searchMovieList.json?key=\" + key\n",
    "parameter = {\"directorNm\": \"봉준호\"}\n",
    "req = requests.get(url, parameter)\n",
    "#공공데이터에 등록된 xml파일에 접\n",
    "html= req.json()\n",
    "html\n",
    "DF = pd.DataFrame(html['movieListResult'][\"movieList\"])\n",
    "## 연도로 다시 정렬\n",
    "DF = DF.sort_values(\"prdtYear\")\n",
    "\n",
    "## 컬럼 형식 바꾸기\n",
    "DF['directors'] = DF['directors'].apply(lambda x : x[0]['peopleNm'])\n",
    "DF['companys'] = DF['companys'].apply(lambda x : x[0]['companyNm'] if x else x)\n",
    "\n",
    "DF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 문제2: \n",
    "<div style = \"margin-top:30px\">\n",
    "\n",
    "일별 박스오피스 API를 이용하여 2018년의 한국 영화 일별 박스오피스 데이터를 생성하여 csv파일로 저장하세요.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 날짜를 먼저 만들어준다. -> 시간 데이터 만들기\n",
    "date = pd.date_range('20180101', '20181231')\n",
    "date\n",
    "\n",
    "Time = []\n",
    "for time in date:    \n",
    "    Time.append(date.strftime(\"%Y%m%d\").tolist())\n",
    "    \n",
    "time_list=Time[0] ##12번 반복됨을 알아서 그중에서 하나만 사용\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "key = 'a8e597633acca03091ad5fba598b58a7'\n",
    "url = \"http://kobis.or.kr/kobisopenapi/webservice/rest/boxoffice/searchDailyBoxOfficeList.json?key=\" + key + \"&targetDt=\"\n",
    "df_default = pd.DataFrame()\n",
    "for k in range(len(time_list)):\n",
    "    requestData2 = requests.get(url+str(time_list[k])+'')\n",
    "    data_2 = requestData2.json()\n",
    "    data = data_2['boxOfficeResult']['dailyBoxOfficeList']\n",
    "    df = pd.DataFrame.from_dict(data)\n",
    "    df_default = df_default.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_default.to_csv('data_result.csv',encoding='utf-8', index = False) ## 한글이 포함되어 있으므로, encoding에 utf-8을 넣는다.-> 파일을 저장한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 출력을 통해서 확인\n",
    "pd.read_csv('data_result.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem2\n",
    "### 문제 1:  \n",
    "<div style = \"margin-top:30px\">\n",
    "\n",
    "멜론의 Top100 차트 데이터를 크롤링해 곡 명, 가수 명, 앨범 명 데이터를 만들어 봅시다.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "from selenium import webdriver as wd\n",
    "import time\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from itertools import repeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = wd.Chrome('.\\chromedriver') # 크롬드라이버 경로\n",
    "driver.maximize_window() # 크롬창 크기 최대\n",
    "\n",
    "# 드라이버가 해당 url 접속\n",
    "url = 'https://www.melon.com/chart/index.htm' # 멜론차트 페이지\n",
    "driver.get(url)\n",
    "\n",
    "html = driver.page_source # 드라이버 현재 페이지의 html 정보 가져오기 \n",
    "                        # cf) requests.get(url)\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "title = soup.find_all('div', class_ = 'ellipsis rank01')\n",
    "singer = soup.find_all('span', class_ = 'checkEllipsis')\n",
    "album = soup.find_all('div', class_ = 'ellipsis rank03')\n",
    "\n",
    "title_list = []\n",
    "singer_list = []\n",
    "album_list = []\n",
    "\n",
    "length  = len(title) # 100\n",
    "for i in range(0, length, 1):\n",
    "    title_list.append(title[i].text.strip(\"\\n\"))\n",
    "    singer_list.append(singer[i].text)  \n",
    "    album_list.append(album[i].text.strip(\"\\n\"))\n",
    "\n",
    "\n",
    "df_1= pd.DataFrame()\n",
    "df_1['title'] = title_list\n",
    "df_1['singer'] = singer_list\n",
    "df_1['album'] = album_list\n",
    "\n",
    "df_1\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 문제 2:  \n",
    "<div style = \"margin-top:30px\">\n",
    "월간 차트 페이지에서 2021년 1월부터 12월까지의 월간 차트를 모아 하나의 데이터 프레임을 만드세요. 칼럼은 총 8개로 연, 월, 순위, 순위 변동, 곡 명, 가수 명, 앨범 명, 좋아요 수입니다.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reset = pd.DataFrame()## 빈 데이터 프레임 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def melon(mon):\n",
    "    global df_reset\n",
    "        # 크롬드라이버 열기\n",
    "    driver = wd.Chrome('.\\chromedriver') # 크롬드라이버 경로\n",
    "    driver.maximize_window() # 크롬창 크기 최대\n",
    "\n",
    "    # 드라이버가 해당 url 접속\n",
    "    url = 'https://www.melon.com/chart/index.htm' # 멜론차트 페이지\n",
    "    driver.get(url)\n",
    "\n",
    "    # 차트파인더 클릭\n",
    "    driver.find_element_by_xpath('//*[@id=\"gnb_menu\"]/ul[1]/li[1]/div/div/button/span').click()\n",
    "\n",
    "    # 연대선택, 연도선택, 월선택, 장르선택\n",
    "\n",
    "    # 월간차트 클릭\n",
    "    driver.find_element_by_xpath('//*[@id=\"d_chart_search\"]/div/h4[2]/a').click()\n",
    "    time.sleep(2)\n",
    "\n",
    "    # 연대선택 2020년대 클릭\n",
    "    driver.find_element_by_xpath('//*[@id=\"d_chart_search\"]/div/div/div[1]/div[1]/ul/li[1]/span/label').click()\n",
    "    time.sleep(2)\n",
    "\n",
    "    # 연도선택 2021년 클릭\n",
    "    driver.find_element_by_xpath('//*[@id=\"d_chart_search\"]/div/div/div[2]/div[1]/ul/li[2]/span/label').click()\n",
    "    time.sleep(2)\n",
    "\n",
    "    # 월선택 month월 클릭\n",
    "    driver.find_element_by_xpath('//*[@id=\"d_chart_search\"]/div/div/div[3]/div[1]/ul/li['+str(mon)+']/span/label').click()\n",
    "    time.sleep(2)\n",
    "\n",
    "    # 장르선택 종합 클릭\n",
    "    driver.find_element_by_xpath('//*[@id=\"d_chart_search\"]/div/div/div[5]/div[1]/ul/li[1]/span/label').click()\n",
    "    time.sleep(2)\n",
    "\n",
    "    # 검색버튼 클릭\n",
    "    driver.find_element_by_xpath('//*[@id=\"d_srch_form\"]/div[2]/button/span/span').click()\n",
    "    time.sleep(2)\n",
    "\n",
    "    html = driver.page_source # 드라이버 현재 페이지의 html 정보 가져오기 \n",
    "                           \n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    # print(soup.prettify()) ## beautiful soup 에서 가져온 html 확인\n",
    "\n",
    "    # html 내에서 각 테그의 특징을 가져와서 이를 통해서 find_all을 실행한다.\n",
    "    title = soup.find_all('div', class_ = 'ellipsis rank01')\n",
    "    singer = soup.find_all('span', class_ = 'checkEllipsis')\n",
    "    album = soup.find_all('div', class_ = 'ellipsis rank03')\n",
    "    diff = soup.find_all('span', class_ = 'wrap_rank')\n",
    "    like = soup.find_all('span', class_ = 'cnt')\n",
    "\n",
    "    ## 리스트 초기화\n",
    "    year_list = []\n",
    "    month_list = []\n",
    "    rank_list = []\n",
    "    diff_list = []\n",
    "    title_list = []\n",
    "    singer_list = []\n",
    "    album_list = []\n",
    "    like_list = []\n",
    "\n",
    "    length  = len(title) # 100\n",
    "    for i in range(0, length, 1):\n",
    "\n",
    "        ## 만들어준 리스트에 append를 통해서 담아준다.\n",
    "        year_list.append(2021)\n",
    "        month_list.append(mon)\n",
    "        rank_list.append(i+1)\n",
    "        title_list.append(title[i].text.strip(\"\\n\").replace(\"\\n\", \" \")) ## 결과를 보니까 중간에 들어간 \\n 존재해서 이를 띄어쓰기로 대체\n",
    "        singer_list.append(singer[i].text)  \n",
    "        like_list.append(like[i].text.strip(\"\\n\")[4:])\n",
    "        album_list.append(album[i].text.strip(\"\\n\"))\n",
    "        diff_list.append(diff[i+10]['title'])\n",
    "\n",
    "    ## 빈 데이터 프레임을 만들어서 담아준다 -> 함수를 돌릴 때, 각 함수에서 나온 결과를 담아놓는 dataframe이 필요\n",
    "    ## 이를 계속 append 해서 최종 dataframe을 만든다.\n",
    "    df= pd.DataFrame()\n",
    "    df[\"year\"] = year_list\n",
    "    df[\"month\"] = month_list\n",
    "    df['rank'] = rank_list\n",
    "    df['diff'] = diff_list\n",
    "    df['title'] = title_list\n",
    "    df['singer'] = singer_list\n",
    "    df['album'] = album_list\n",
    "    df['like'] = like_list\n",
    "    \n",
    "    df_reset = df_reset.append(df) #dataframe 결과를 쌓아주는 역할을 한다.\n",
    "    driver.close()##드라이버가 여러개 열리면 복잡하므로 사용후 닫아준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reset = pd.DataFrame()## 빈 데이터 프레임 만들기\n",
    "for i in range(1, 13, 1): ## 반복문으로 12개월을 한번에 돌리면 끝\n",
    "    melon(i)\n",
    "df_reset = df_reset.reset_index(drop=True)   \n",
    "df_reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
